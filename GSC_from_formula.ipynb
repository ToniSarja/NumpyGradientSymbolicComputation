{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa19663-8b7b-444b-9194-2ea7b7444977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-13.7  15.4 -24.8 -13.8  16.4 -27.2]\n",
      " [-13.9  17.4 -29.6 -14.   18.4 -32. ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define matrices A, B, C (example 2x2 matrices)\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "C = np.array([[9, 10], [11, 12]])\n",
    "\n",
    "# Define vectors r_left and r_right (example 3-dimensional vectors)\n",
    "r_left = np.array([1, 0, -1])\n",
    "r_right = np.array([2, -2, 3])\n",
    "\n",
    "# Compute the Kronecker products\n",
    "kron_A_rleft = np.kron(A, r_left)\n",
    "kron_A_rright = np.kron(A, r_right)\n",
    "kron_B_rleft = np.kron(B, r_left)\n",
    "kron_C_rright = np.kron(C, r_right)\n",
    "\n",
    "# Combine according to the given expression\n",
    "result = (0.7 * kron_A_rleft + 0.4 * kron_A_rright +\n",
    "          0.2 * kron_B_rleft - 0.9 * kron_C_rright)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578ce4e2-7358-45fe-a2ca-fc17cc67d02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.4496\n",
      "Epoch 100, Loss: 0.0882\n",
      "Epoch 200, Loss: 0.0880\n",
      "Epoch 300, Loss: 0.0880\n",
      "Epoch 400, Loss: 0.0880\n",
      "Epoch 500, Loss: 0.0880\n",
      "Epoch 600, Loss: 0.0880\n",
      "Epoch 700, Loss: 0.0880\n",
      "Epoch 800, Loss: 0.0880\n",
      "Epoch 900, Loss: 0.0880\n",
      "[[ 0.01709714  0.30238564 -0.22541287]\n",
      " [ 0.16231905  0.12806729 -0.09889405]\n",
      " [ 0.3088229   0.08402548  0.10988065]] [[ 0.33883426  0.04219613  0.55478878]\n",
      " [-0.24050283 -0.09667679  0.58190136]\n",
      " [ 0.0173181   0.68098806 -0.14339826]] [[-0.16754943 -0.19984807 -0.3025727 ]\n",
      " [-0.38942973 -0.13382882 -0.25536531]\n",
      " [ 0.03717029 -0.19384111 -0.08223671]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_dummy_data(csv_file, num_samples=100):\n",
    "    \"\"\"\n",
    "    Generate a dummy dataset and save it to a CSV file.\n",
    "    \"\"\"\n",
    "    r_left = np.random.rand(num_samples, 3)\n",
    "    r_right = np.random.rand(num_samples, 3)\n",
    "    targets = np.random.rand(num_samples, 3)\n",
    "    \n",
    "    data = np.hstack((r_left, r_right, targets))\n",
    "    columns = [f\"r_left_{i}\" for i in range(3)] + [f\"r_right_{i}\" for i in range(3)] + [f\"target_{i}\" for i in range(3)]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.to_csv(csv_file, index=False)\n",
    "\n",
    "def load_data(csv_file):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(csv_file)\n",
    "    r_left = data.iloc[:, :3].values  # First 3 columns are r_left\n",
    "    r_right = data.iloc[:, 3:6].values  # Next 3 columns are r_right\n",
    "    targets = data.iloc[:, 6:].values  # Remaining columns are targets\n",
    "    return r_left, r_right, targets\n",
    "\n",
    "def neural_layer(A, B, C, r_left, r_right):\n",
    "    \"\"\"\n",
    "    Compute the output based on the given formula.\n",
    "    \"\"\"\n",
    "    term1 = 0.7 * np.dot(r_left, A.T)  # Matrix multiplication\n",
    "    term2 = 0.4 * np.dot(r_right, A.T)\n",
    "    term3 = 0.2 * np.dot(r_left, B.T)\n",
    "    term4 = -0.9 * np.dot(r_right, C.T)\n",
    "    \n",
    "    output = term1 + term2 + term3 + term4\n",
    "    return output\n",
    "\n",
    "def mean_squared_error(predictions, targets):\n",
    "    \"\"\"\n",
    "    Compute the mean squared error loss.\n",
    "    \"\"\"\n",
    "    return np.mean((predictions - targets) ** 2)\n",
    "\n",
    "def train_model(A, B, C, r_left, r_right, targets, learning_rate=0.01, epochs=1000):\n",
    "    \"\"\"\n",
    "    Train the model using gradient descent.\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        output = neural_layer(A, B, C, r_left, r_right)\n",
    "        loss = mean_squared_error(output, targets)\n",
    "        \n",
    "        error = output - targets\n",
    "        \n",
    "        # Compute gradients\n",
    "        grad_A = 0.7 * np.dot(error.T, r_left) + 0.4 * np.dot(error.T, r_right)\n",
    "        grad_B = 0.2 * np.dot(error.T, r_left)\n",
    "        grad_C = -0.9 * np.dot(error.T, r_right)\n",
    "        \n",
    "        # Update weights\n",
    "        A -= learning_rate * grad_A\n",
    "        B -= learning_rate * grad_B\n",
    "        C -= learning_rate * grad_C\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    return A, B, C\n",
    "\n",
    "# Generate and load dummy data\n",
    "csv_file = \"dummy_data.csv\"\n",
    "generate_dummy_data(csv_file)\n",
    "r_left, r_right, targets = load_data(csv_file)\n",
    "\n",
    "# Initialize weights\n",
    "A = np.random.rand(3, 3)\n",
    "B = np.random.rand(3, 3)\n",
    "C = np.random.rand(3, 3)\n",
    "\n",
    "# Train the model\n",
    "A, B, C = train_model(A, B, C, r_left, r_right, targets)\n",
    "print(A, B, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f961ce-abbc-4b50-808e-ba05e0351ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
